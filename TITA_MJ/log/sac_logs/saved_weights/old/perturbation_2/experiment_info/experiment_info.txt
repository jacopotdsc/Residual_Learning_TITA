Enviroment: Tita-v0
Observation space: 70 x 1 (stacked frames)
Action space: (8,)
Action size: 120.0

	Action Scale: 10.0
	Action Repeat: 1
	cost_action_nn: -0.01
	cost_action_rate: -0.01
	cost_ang_vel_xy: -0.01
	cost_early_termination: -100
	cost_lin_vel_z: -0.05
	cost_orientation: -0.1
	cost_vel_feet: -3.0
	has_nan: -1.0
	reward_is_alive: 2
	reward_tracking_ang_vel: 1
	reward_tracking_lin_vel: 1

Starting training enviroment Tita-v0

SAC Buffer parameters:
	 Total size: 20_000
	 Buffer num: 4
	 Stack num: 1
Train Buffer - Batch Observation Shape: (1, 70)
Train Buffer - Single Sample Shape: (70,)
Test Buffer - Batch Observation Shape: (1, 70)
Test Buffer - Single Sample Shape: (70,)
Actor file not found: /home/ubuntu/Desktop/repo_rl/TITA-dynamic-obstacle-avoidance/TITA_MJ/log/weights_saved/stand_up_randomize_reset.pt
 -> Continuing training from scratch.

SAC Trainer parameters:
	 Num train/test envs 4 / 1
	 learning rate: 1e-05
	 hidden sizes: [256, 128, 64]
	 Max epochs: 30
	 Batch size: 256
	 Epoch num steps: 4000
	 Collection step num env steps: 400 , roullout:  100
	 Update step num gradient steps per sample: 1024.0
	 Test step num episodes: 1 


Total training time: 9m, 44.69s

Training completed!
Logs saved to /home/ubuntu/Desktop/repo_rl/TITA-dynamic-obstacle-avoidance/TITA_MJ/log/sac_logs
Saving weights in /home/ubuntu/Desktop/repo_rl/TITA-dynamic-obstacle-avoidance/TITA_MJ/log/sac_logs
Saved actor weights to /home/ubuntu/Desktop/repo_rl/TITA-dynamic-obstacle-avoidance/TITA_MJ/log/sac_logs/weights/sac_day_2026_01_21_time_10_09_56/final/final_actor_state_dict.pt
Saved critic1 weights to /home/ubuntu/Desktop/repo_rl/TITA-dynamic-obstacle-avoidance/TITA_MJ/log/sac_logs/weights/sac_day_2026_01_21_time_10_09_56/final/final_critic_state_dict_1.pt
Saved critic2 weights to /home/ubuntu/Desktop/repo_rl/TITA-dynamic-obstacle-avoidance/TITA_MJ/log/sac_logs/weights/sac_day_2026_01_21_time_10_09_56/final/final_critic_state_dict_2.pt